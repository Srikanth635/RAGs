{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-18T15:08:13.440164Z",
     "start_time": "2025-03-18T15:06:06.607422Z"
    }
   },
   "source": [
    "# pip install git+https://github.com/huggingface/transformers@v4.49.0-Gemma-3   ## To install transformers 4.50.0.dev0\n",
    "from unsloth import FastModel\n",
    "import torch\n",
    "\n",
    "fourbit_models = [\n",
    "    # 4bit dynamic quants for superior accuracy and low memory use\n",
    "    \"unsloth/gemma-3-1b-it-unsloth-bnb-4bit\",\n",
    "    \"unsloth/gemma-3-4b-it-unsloth-bnb-4bit\",\n",
    "    \"unsloth/gemma-3-12b-it-unsloth-bnb-4bit\",\n",
    "    \"unsloth/gemma-3-27b-it-unsloth-bnb-4bit\",\n",
    "\n",
    "    # Other popular models!\n",
    "    \"unsloth/Llama-3.1-8B\",\n",
    "    \"unsloth/Llama-3.2-3B\",\n",
    "    \"unsloth/Llama-3.3-70B\",\n",
    "    \"unsloth/mistral-7b-instruct-v0.3\",\n",
    "    \"unsloth/Phi-4\",\n",
    "] # More models at https://huggingface.co/unsloth\n",
    "\n",
    "model, tokenizer = FastModel.from_pretrained(\n",
    "    model_name = \"unsloth/gemma-3-12b-it\",\n",
    "    max_seq_length = 2048, # Choose any for long context!\n",
    "    load_in_4bit = True,  # 4 bit quantization to reduce memory\n",
    "    load_in_8bit = False, # [NEW!] A bit more accurate, uses 2x memory\n",
    "    full_finetuning = False, # [NEW!] We have full finetuning now!\n",
    "    # token = \"hf_...\", # use one if using gated models\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/malineni/envs/unsloth/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2025.3.15: Fast Gemma3 patching. Transformers: 4.50.0.dev0.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 4070. Num GPUs = 1. Max memory: 11.719 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.9. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [01:56<00:00, 38.95s/it]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit the quantized model. If you want to dispatch the model on the CPU or the disk while keeping these modules in 32-bit, you need to set `llm_int8_enable_fp32_cpu_offload=True` and pass a custom `device_map` to `from_pretrained`. Check https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu for more details. ",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 20\u001B[39m\n\u001B[32m      3\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\n\u001B[32m      5\u001B[39m fourbit_models = [\n\u001B[32m      6\u001B[39m     \u001B[38;5;66;03m# 4bit dynamic quants for superior accuracy and low memory use\u001B[39;00m\n\u001B[32m      7\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33munsloth/gemma-3-1b-it-unsloth-bnb-4bit\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m     17\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33munsloth/Phi-4\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m     18\u001B[39m ] \u001B[38;5;66;03m# More models at https://huggingface.co/unsloth\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m20\u001B[39m model, tokenizer = \u001B[43mFastModel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     21\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43munsloth/gemma-3-12b-it\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     22\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmax_seq_length\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m2048\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;66;43;03m# Choose any for long context!\u001B[39;49;00m\n\u001B[32m     23\u001B[39m \u001B[43m    \u001B[49m\u001B[43mload_in_4bit\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# 4 bit quantization to reduce memory\u001B[39;49;00m\n\u001B[32m     24\u001B[39m \u001B[43m    \u001B[49m\u001B[43mload_in_8bit\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;66;43;03m# [NEW!] A bit more accurate, uses 2x memory\u001B[39;49;00m\n\u001B[32m     25\u001B[39m \u001B[43m    \u001B[49m\u001B[43mfull_finetuning\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;66;43;03m# [NEW!] We have full finetuning now!\u001B[39;49;00m\n\u001B[32m     26\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# token = \"hf_...\", # use one if using gated models\u001B[39;49;00m\n\u001B[32m     27\u001B[39m \u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/envs/unsloth/lib/python3.11/site-packages/unsloth/models/loader.py:713\u001B[39m, in \u001B[36mFastModel.from_pretrained\u001B[39m\u001B[34m(model_name, max_seq_length, dtype, load_in_4bit, load_in_8bit, full_finetuning, token, device_map, rope_scaling, fix_tokenizer, trust_remote_code, use_gradient_checkpointing, resize_model_vocab, revision, return_logits, fullgraph, use_exact_model_name, *args, **kwargs)\u001B[39m\n\u001B[32m    710\u001B[39m is_vlm = is_vlm \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(model_config, \u001B[33m\"\u001B[39m\u001B[33mvision_config\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    711\u001B[39m auto_model = AutoModelForVision2Seq \u001B[38;5;28;01mif\u001B[39;00m is_vlm \u001B[38;5;28;01melse\u001B[39;00m AutoModelForCausalLM\n\u001B[32m--> \u001B[39m\u001B[32m713\u001B[39m model, tokenizer = \u001B[43mFastBaseModel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    714\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m        \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    715\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmax_seq_length\u001B[49m\u001B[43m    \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_seq_length\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    716\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m             \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43m_get_dtype\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    717\u001B[39m \u001B[43m    \u001B[49m\u001B[43mload_in_4bit\u001B[49m\u001B[43m      \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mload_in_4bit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    718\u001B[39m \u001B[43m    \u001B[49m\u001B[43mload_in_8bit\u001B[49m\u001B[43m      \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mload_in_8bit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    719\u001B[39m \u001B[43m    \u001B[49m\u001B[43mfull_finetuning\u001B[49m\u001B[43m   \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mfull_finetuning\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    720\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m             \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    721\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdevice_map\u001B[49m\u001B[43m        \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_map\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    722\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtrust_remote_code\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrust_remote_code\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    723\u001B[39m \u001B[43m    \u001B[49m\u001B[43mrevision\u001B[49m\u001B[43m          \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mrevision\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mis_peft\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    724\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmodel_types\u001B[49m\u001B[43m       \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_types\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    725\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtokenizer_name\u001B[49m\u001B[43m    \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mtokenizer_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    726\u001B[39m \u001B[43m    \u001B[49m\u001B[43mauto_model\u001B[49m\u001B[43m        \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mauto_model\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    727\u001B[39m \u001B[43m    \u001B[49m\u001B[43muse_gradient_checkpointing\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43muse_gradient_checkpointing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    728\u001B[39m \u001B[43m    \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    729\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    731\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m resize_model_vocab \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    732\u001B[39m     model.resize_token_embeddings(resize_model_vocab)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/envs/unsloth/lib/python3.11/site-packages/unsloth/models/vision.py:301\u001B[39m, in \u001B[36mFastBaseModel.from_pretrained\u001B[39m\u001B[34m(model_name, max_seq_length, dtype, load_in_4bit, load_in_8bit, full_finetuning, token, device_map, trust_remote_code, model_types, tokenizer_name, auto_model, use_gradient_checkpointing, **kwargs)\u001B[39m\n\u001B[32m    299\u001B[39m torch_dtype = dtype\n\u001B[32m    300\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m do_forced_float32: torch_dtype = torch.bfloat16\n\u001B[32m--> \u001B[39m\u001B[32m301\u001B[39m model = \u001B[43mauto_model\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    302\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    303\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdevice_map\u001B[49m\u001B[43m              \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_map\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    304\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtorch_dtype\u001B[49m\u001B[43m             \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mtorch_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    305\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# quantization_config   = bnb_config,\u001B[39;49;00m\n\u001B[32m    306\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m                   \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    307\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtrust_remote_code\u001B[49m\u001B[43m       \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrust_remote_code\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    308\u001B[39m \u001B[43m    \u001B[49m\u001B[43mattn_implementation\u001B[49m\u001B[43m     \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mattn_implementation\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    309\u001B[39m \u001B[43m    \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    310\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    311\u001B[39m \u001B[38;5;66;03m# Return old flag\u001B[39;00m\n\u001B[32m    312\u001B[39m os.environ[\u001B[33m\"\u001B[39m\u001B[33mHF_HUB_ENABLE_HF_TRANSFER\u001B[39m\u001B[33m\"\u001B[39m] = old_hf_transfer\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/envs/unsloth/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:564\u001B[39m, in \u001B[36m_BaseAutoModelClass.from_pretrained\u001B[39m\u001B[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001B[39m\n\u001B[32m    562\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mtype\u001B[39m(config) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mcls\u001B[39m._model_mapping.keys():\n\u001B[32m    563\u001B[39m     model_class = _get_model_class(config, \u001B[38;5;28mcls\u001B[39m._model_mapping)\n\u001B[32m--> \u001B[39m\u001B[32m564\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmodel_class\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    565\u001B[39m \u001B[43m        \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43mmodel_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mhub_kwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[32m    566\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    567\u001B[39m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m    568\u001B[39m     \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mUnrecognized configuration class \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconfig.\u001B[34m__class__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m for this kind of AutoModel: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mcls\u001B[39m.\u001B[34m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m    569\u001B[39m     \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mModel type should be one of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[33m'\u001B[39m\u001B[33m, \u001B[39m\u001B[33m'\u001B[39m.join(c.\u001B[34m__name__\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mfor\u001B[39;00m\u001B[38;5;250m \u001B[39mc\u001B[38;5;250m \u001B[39m\u001B[38;5;129;01min\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28mcls\u001B[39m._model_mapping.keys())\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    570\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/envs/unsloth/lib/python3.11/site-packages/transformers/modeling_utils.py:273\u001B[39m, in \u001B[36mrestore_default_torch_dtype.<locals>._wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    271\u001B[39m old_dtype = torch.get_default_dtype()\n\u001B[32m    272\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m273\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    274\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    275\u001B[39m     torch.set_default_dtype(old_dtype)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/envs/unsloth/lib/python3.11/site-packages/transformers/modeling_utils.py:4394\u001B[39m, in \u001B[36mPreTrainedModel.from_pretrained\u001B[39m\u001B[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001B[39m\n\u001B[32m   4391\u001B[39m     device_map = infer_auto_device_map(model, dtype=target_dtype, **device_map_kwargs)\n\u001B[32m   4393\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m hf_quantizer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m4394\u001B[39m         \u001B[43mhf_quantizer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mvalidate_environment\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice_map\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdevice_map\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   4396\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m device_map \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m   4397\u001B[39m     model.tie_weights()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/envs/unsloth/lib/python3.11/site-packages/transformers/quantizers/quantizer_bnb_4bit.py:103\u001B[39m, in \u001B[36mBnb4BitHfQuantizer.validate_environment\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m    101\u001B[39m         \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[32m    102\u001B[39m     \u001B[38;5;28;01melif\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mcpu\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m device_map_without_lm_head.values() \u001B[38;5;129;01mor\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mdisk\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m device_map_without_lm_head.values():\n\u001B[32m--> \u001B[39m\u001B[32m103\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m    104\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33mSome modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit the \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    105\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33mquantized model. If you want to dispatch the model on the CPU or the disk while keeping these modules \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    106\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33min 32-bit, you need to set `llm_int8_enable_fp32_cpu_offload=True` and pass a custom `device_map` to \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    107\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33m`from_pretrained`. Check \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    108\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33mhttps://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    109\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33mfor more details. \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    110\u001B[39m         )\n\u001B[32m    112\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m version.parse(importlib.metadata.version(\u001B[33m\"\u001B[39m\u001B[33mbitsandbytes\u001B[39m\u001B[33m\"\u001B[39m)) < version.parse(\u001B[33m\"\u001B[39m\u001B[33m0.39.0\u001B[39m\u001B[33m\"\u001B[39m):\n\u001B[32m    113\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m    114\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mYou have a version of `bitsandbytes` that is not compatible with 4bit inference and training\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    115\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33m make sure you have the latest version of `bitsandbytes` installed\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    116\u001B[39m     )\n",
      "\u001B[31mValueError\u001B[39m: Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit the quantized model. If you want to dispatch the model on the CPU or the disk while keeping these modules in 32-bit, you need to set `llm_int8_enable_fp32_cpu_offload=True` and pass a custom `device_map` to `from_pretrained`. Check https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu for more details. "
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T14:36:06.783315Z",
     "start_time": "2025-03-18T14:36:05.682648Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = FastModel.get_peft_model(\n",
    "    model,\n",
    "    finetune_vision_layers     = False, # Turn off for just text!\n",
    "    finetune_language_layers   = True,  # Should leave on!\n",
    "    finetune_attention_modules = True,  # Attention good for GRPO\n",
    "    finetune_mlp_modules       = True,  # SHould leave on always!\n",
    "\n",
    "    r = 8,           # Larger = higher accuracy, but might overfit\n",
    "    lora_alpha = 8,  # Recommended alpha == r at least\n",
    "    lora_dropout = 0,\n",
    "    bias = \"none\",\n",
    "    random_state = 3407,\n",
    ")"
   ],
   "id": "1d4172e2d54165ca",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Making `model.base_model.model.language_model.model` require gradients\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T14:36:51.092115Z",
     "start_time": "2025-03-18T14:36:51.089031Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "def read_markdown_files(directory):\n",
    "    markdown_contents = []\n",
    "    text_contents = []\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(\".md\"):\n",
    "                file_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    with open(file_path, \"r\", encoding=\"utf-8\", errors='replace') as f:\n",
    "                        content = f.read()\n",
    "                        markdown_contents.append(content)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading file {file_path}: {e}\")\n",
    "            elif file.endswith(\".txt\"):\n",
    "                file_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    with open(file_path, \"r\", encoding=\"utf-8\", errors='replace') as f:\n",
    "                        content = f.read()\n",
    "                        text_contents.append(content)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading file {file_path}: {e}\")\n",
    "\n",
    "    return markdown_contents, text_contents"
   ],
   "id": "536c76a653eb9a4b",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T14:37:05.141376Z",
     "start_time": "2025-03-18T14:37:05.057680Z"
    }
   },
   "cell_type": "code",
   "source": [
    "docs_content, text_content = read_markdown_files(os.path.join(os.curdir, \"../documentation\"))\n",
    "print(docs_content[2])"
   ],
   "id": "ae89c71ceff06ba2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can usability models help robots learn and improve interaction quality through task data and user feedback?Yes, usability models can indeed support learning in robots to enhance usability over time. In fact, considering usability during the design and development of robotic systems is of paramount importance.\n",
      "\n",
      "## Use of Usability Models in Robots\n",
      "\n",
      "Usability models can serve as a guide for how robots should interact with users, helping them to achieve their goals efficiently, effectively, and with a high degree of satisfaction. Over time, as the robot interacts more with its users, it can use these models to learn and adapt itself to better meet the user's needs.\n",
      "\n",
      "## Task Data & User Feedback\n",
      "\n",
      "### Task Data\n",
      "\n",
      "Task data refers to the specific tasks that the robot is programmed to perform. This data can include information on the success or failure of tasks, the time taken to complete tasks, and other metrics that are relevant to the task's performance.\n",
      "\n",
      "Robots can use this data to improve their performance in several ways. For instance:\n",
      "\n",
      "1. **Adaptive Learning**: Robots can recognize patterns in task data, which allows them to predict future outcomes and adjust their behavior accordingly. This results in more efficient task execution.\n",
      "\n",
      "2. **Incremental Learning**: Based on the task data, robots can incrementally refine their skills over time. They can learn more about the tasks they perform and effectively improve their efficiency and accuracy.\n",
      "\n",
      "### User Feedback\n",
      "\n",
      "User feedback is another essential part of the learning process for robots. Feedback can come in various forms, such as direct user ratings, indirect signals from user behavior, or even real-time emotional responses.\n",
      "\n",
      "User feedback can provide valuable insights into how users perceive the robot's performance and interaction quality. For instance:\n",
      "\n",
      "1. **Calibrating Interaction**: Feedback helps robots learn and adapt their characteristics (behavior, speech, movement) to better align with user's preferences, thus enhancing the interaction quality.\n",
      "\n",
      "2. **Performance Enhancement**: Negative feedback can help identify what is not working and provide a chance to improve those areas. Conversely, positive feedback encourages the reinforcement of behaviors that users find satisfying.\n",
      "\n",
      "In summary, robots can leverage usability models, task data and user feedback to self-adjust and improve over time â€” enhancing usability and interaction quality for a more user-tailored experience.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T14:37:39.693811Z",
     "start_time": "2025-03-18T14:37:39.673466Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import Dataset, load_dataset, concatenate_datasets\n",
    "data1 = {\"text\": text_content}\n",
    "datasets1 = Dataset.from_dict(data1)\n",
    "data2 = {\"text\": docs_content}\n",
    "datasets2 = Dataset.from_dict(data2)\n",
    "datasets = concatenate_datasets([datasets1, datasets2])\n",
    "EOS_TOKEN = tokenizer.eos_token"
   ],
   "id": "4b73d48380ae4525",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T14:37:45.781863Z",
     "start_time": "2025-03-18T14:37:45.764811Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def formatting_prompts_func(examples):\n",
    "    return { \"text\" : [example + EOS_TOKEN for example in examples[\"text\"]] }\n",
    "datasets = datasets.map(formatting_prompts_func, batched = True,)"
   ],
   "id": "ad91c1bbf88ddbb7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 574/574 [00:00<00:00, 48563.40 examples/s]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T14:37:57.321244Z",
     "start_time": "2025-03-18T14:37:57.318900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for row in datasets[3:4][\"text\"]:\n",
    "    print(\"=========================\")\n",
    "    print(row)"
   ],
   "id": "c14b5c0c6766fffb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================\n",
      "query: cut the apple into 4 equal pieces on the table using the sharp black knife\n",
      "\n",
      "\n",
      "response: comprehensive cram action designator in lisp format is as below\n",
      "(an action\n",
      "    (type cutting)\n",
      "    (object (an object\n",
      "              (type apple)\n",
      "              (name \"standard-apple\")\n",
      "              (properties (size \"medium\")\n",
      "                          (texture \"smooth\")\n",
      "                          (color \"red\")))))\n",
      "    (tool (a tool\n",
      "            (type knife)\n",
      "            (name \"sharp-black-knife\")\n",
      "            (properties (sharpness \"very-high\")\n",
      "                        (size \"medium\")\n",
      "                        (material \"steel\")\n",
      "                        (weight \"light\")\n",
      "                        (color \"black\")\n",
      "                        (edge \"smooth\")))))\n",
      "    (location (a location\n",
      "                (type table)\n",
      "                (name \"kitchen-table\")\n",
      "                (properties (material \"wood\")\n",
      "                            (height 0.9)\n",
      "                            (accessibility \"high\")\n",
      "                            (surface-type \"stable\")))))\n",
      "    (goal (for-object (an object\n",
      "                        (type apple)\n",
      "                        (to be-cut-into-pieces\n",
      "                          (details (type \"quarter\")\n",
      "                                   (size \"equal\")\n",
      "                                   (quantity \"4\"))))))\n",
      "    (task-constraints\n",
      "      (cut-type \"quartered\")\n",
      "      (cut-uniformly \"true\")\n",
      "      (remove-core \"none\")\n",
      "      (remove-seeds \"none\")\n",
      "      (maintain-shape-integrity \"high\"))\n",
      "    (motion-constraints\n",
      "      (kinematic-constraints\n",
      "        (degrees-of-freedom 6)\n",
      "        (workspace (boundaries (x-min 0)\n",
      "                              (x-max 1000)\n",
      "                              (y-min 0)\n",
      "                              (y-max 1000)\n",
      "                              (z-min 0)\n",
      "                              (z-max 500))\n",
      "                   (singularity-tolerance 0.01))\n",
      "        (path-constraints (trajectory-smoothness 0.95)\n",
      "                          (collision-avoidance (enabled true)\n",
      "                                              (proximity-threshold 20))))\n",
      "      (dynamic-constraints\n",
      "        (force-control (normal-force 10)\n",
      "                       (shearing-force 5))\n",
      "        (vibration-control (damping-coefficient 0.8))\n",
      "        (torque-limits (joint-1 (max-torque 10))\n",
      "                       (joint-2 (max-torque 15)))\n",
      "        (inertia-compensation (object-inertia (x 0.003)\n",
      "                                            (y 0.003)\n",
      "                                            (z 0.002))))\n",
      "      (control-constraints\n",
      "        (motion-control (control-mode \"hybrid_force_position\")\n",
      "                        (gain-tuning (proportional-gain 1.0)\n",
      "                                     (derivative-gain 0.6)))\n",
      "        (trajectory-execution (sampling-rate 1000)\n",
      "                              (jerk-limit 30)))\n",
      "      (environmental-constraints\n",
      "        (surface (material \"wood\")\n",
      "                 (friction-coefficient 0.6)\n",
      "                 (flatness-tolerance 0.02))\n",
      "        (obstacle-avoidance (obstacles (type \"bottle\")\n",
      "                                      (position (x 300)\n",
      "                                                (y 300)\n",
      "                                                (z 0))\n",
      "                                      (dimensions (radius 50)))\n",
      "                            (avoidance-radius 20)))\n",
      "      (feedback-constraints\n",
      "        (sensors (force-sensor (sensitivity 0.1)\n",
      "                               (range 30))\n",
      "                 (camera (resolution (width 1920)\n",
      "                                    (height 1080))\n",
      "                         (field-of-view 90)\n",
      "                         (frame-rate 30))\n",
      "                 (tactile-sensor (resolution 0.01)\n",
      "                                 (sensitivity 0.05)))\n",
      "        (latency (control-loop 5)\n",
      "                 (sensor-update-rate 20)))\n",
      "      (safety-constraints\n",
      "        (force-limits (max-interaction-force 15)\n",
      "                      (human-contact-force-threshold 3))\n",
      "        (tool-safety (tool-storage-position (x 0)\n",
      "                                           (y 0)\n",
      "                                           (z 50))\n",
      "                      (disable-tool-when-idle true))\n",
      "        (collision-safety (emergency-stop (trigger-force 10)\n",
      "                                         (response-time 0.1)))))\n",
      "  (flanagan-motion-phases\n",
      "    (pre-motion-phase\n",
      "      (predictive-model\n",
      "        (expected-trajectory \"smooth downward quartering\")\n",
      "        (force-model\n",
      "          (initial-force 1.0)\n",
      "          (resistance-range))\n",
      "        (tool-model\n",
      "          (sharpness \"very-high\")\n",
      "          (length 15)))\n",
      "      (motion-planning\n",
      "        (trajectory \"controlled downward cut\")\n",
      "        (obstacle-avoidance \"none\")\n",
      "        (energy-efficiency \"optimized\")))\n",
      "    (initiation-phase\n",
      "      (initial-state\n",
      "        (robot-position)\n",
      "        (object-position '(0.5 0 0.1))\n",
      "        (tool-position '(0.4 -0.2 0.3)))\n",
      "      (motion-initialization\n",
      "        (joint-activation\n",
      "          (joint1 40)\n",
      "          (joint2 25))\n",
      "        (velocity-profile \"linear ramp-up\")))\n",
      "    (execution-phase\n",
      "      (feedforward-control\n",
      "        (predicted-forces\n",
      "          (initial-force 1.0)\n",
      "          (cutting-force-range))\n",
      "        (predicted-positions\n",
      "          (start '(0.4 -0.2 0.3))\n",
      "          (end '(0.4 -0.2 0.1)))\n",
      "        (error-tolerance\n",
      "          (position-error 0.01)\n",
      "          (force-error 0.05)))\n",
      "      (feedback-control\n",
      "        (corrective-actions\n",
      "          (adjust-trajectory true)\n",
      "          (increase-force true))\n",
      "        (sensor-feedback\n",
      "          (force 1.2)\n",
      "          (position-error 0.01)\n",
      "          (slip-detected false)))\n",
      "      (sensory-integration\n",
      "        (tactile\n",
      "          (gripper-force 3.0)\n",
      "          (cutting-force 1.2))\n",
      "        (visual\n",
      "          (object-center)\n",
      "          (knife-position '(0.4 -0.2 0.18)))\n",
      "        (proprioceptive\n",
      "          (joint-positions)\n",
      "          (joint-velocities))))\n",
      "    (termination-phase\n",
      "      (end-effector-stabilization\n",
      "        (final-position\n",
      "          (knife-position '(0.4 -0.2 0.0)))\n",
      "        (reset-trajectory \"linear reset to neutral position\"))\n",
      "      (success-verification\n",
      "        (outcome-check\n",
      "          (object-cut true)\n",
      "          (pieces-separated true))\n",
      "        (error-analysis\n",
      "          (cut-quality \"smooth\")\n",
      "          (deviation-from-center 0.01))))))\n",
      "<end_of_turn>\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T14:39:16.350712Z",
     "start_time": "2025-03-18T14:39:12.924639Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "from unsloth import is_bfloat16_supported\n",
    "from unsloth import UnslothTrainer, UnslothTrainingArguments\n",
    "max_seq_length = 2048\n",
    "\n",
    "trainer = UnslothTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = datasets,\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dataset_num_proc = 8,\n",
    "    args = UnslothTrainingArguments(\n",
    "        per_device_train_batch_size = 2,\n",
    "        gradient_accumulation_steps = 8,\n",
    "        warmup_ratio = 0.1,\n",
    "        num_train_epochs = 5,\n",
    "        learning_rate = 5e-5,\n",
    "        embedding_learning_rate = 5e-6,\n",
    "        max_steps=100,\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        logging_steps = 1,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.00,\n",
    "        lr_scheduler_type = \"cosine\",\n",
    "        seed = 3407,\n",
    "        output_dir = \"outputs\",\n",
    "        report_to = \"none\", # Use this for WandB etc\n",
    "    ),\n",
    ")"
   ],
   "id": "a5de395ad32a1df0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Tokenizing [\"text\"] (num_proc=8): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 574/574 [00:02<00:00, 192.52 examples/s]\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T14:58:16.647178Z",
     "start_time": "2025-03-18T14:39:25.104254Z"
    }
   },
   "cell_type": "code",
   "source": "trainer_stats = trainer.train()",
   "id": "47a52677209cb856",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 574 | Num Epochs = 3 | Total steps = 100\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 8\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 8 x 1) = 16\n",
      " \"-____-\"     Trainable parameters = 14,901,248/4,000,000,000 (0.37% trained)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 18:19, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.682600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.883200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.771200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.823200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.746600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.599800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.807400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.759300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.809200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.674200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.686700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.682400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.587400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.535000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.564900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.538900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.457300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.504500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.592500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1.699200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1.554600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1.455800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1.451400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.643600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1.553100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>1.491000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>1.561500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>1.528900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.517600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>1.468200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>1.429300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>1.507900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>1.534700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.356500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>2.956500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>1.577800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>1.503900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>1.479400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.395000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>1.478700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>1.472900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>1.326100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>1.489500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.421400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>1.500700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>1.526500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>1.559700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>1.426500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.408700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>1.291000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>1.421500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>1.290400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>1.527500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>1.499900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>1.254400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>1.424900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>1.207700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>1.363600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.488500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>1.428600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>1.429400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>1.474400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>1.405900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>1.238800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>1.375200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>1.391600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>1.511300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>1.513100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.293300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>2.863600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>1.334200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>1.443900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>1.458000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>1.411200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>1.406700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>1.394300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>1.420100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>1.428400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.401800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>1.407300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>1.269200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>1.395000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>1.310400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>1.378200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>1.426200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>1.392700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>1.477200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>1.349800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.313200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>1.342700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>1.290300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>1.524600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>1.299500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>1.457600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>1.290700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>1.408200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>1.293300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>1.460300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.262800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T15:03:20.056670Z",
     "start_time": "2025-03-18T15:02:58.909037Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import TextIteratorStreamer\n",
    "from threading import Thread\n",
    "text_streamer = TextIteratorStreamer(tokenizer)\n",
    "import textwrap\n",
    "max_print_width = 100\n",
    "\n",
    "prompts = [\n",
    "    \"what is the comprehensive action designator for the task- cut the apple. Give it in lisp format, no further explanation is needed\",\n",
    "    \"what are the flanagan motion phases involved in the task- cut the apple. Give it in json format, no further explanation is needed\",\n",
    "    \"what are the motion constraints involved in the task- cut the apple. Give it in json format, no further explanation is needed\",\n",
    "    \"what are the framenet elements involved in the task- cut the apple. Give it in json format, no further explanation is needed\",\n",
    "    \"what are the object and tools involved in the task- cut the apple. Give it in json format, no further explanation is needed\"\n",
    "]\n",
    "\n",
    "inputs = tokenizer(\n",
    "[\n",
    "    prompts[1]\n",
    "]*1, return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "generation_kwargs = dict(\n",
    "    inputs,\n",
    "    streamer = text_streamer,\n",
    "    max_new_tokens = 2048,\n",
    "    use_cache = True,\n",
    ")\n",
    "thread = Thread(target = model.generate, kwargs = generation_kwargs)\n",
    "thread.start()\n",
    "\n",
    "length = 0\n",
    "for j, new_text in enumerate(text_streamer):\n",
    "    if j == 0:\n",
    "        wrapped_text = textwrap.wrap(new_text, width = max_print_width)\n",
    "        length = len(wrapped_text[-1])\n",
    "        wrapped_text = \"\\n\".join(wrapped_text)\n",
    "        print(wrapped_text, end = \"\")\n",
    "    else:\n",
    "        length += len(new_text)\n",
    "        if length >= max_print_width:\n",
    "            length = 0\n",
    "            print()\n",
    "        print(new_text, end = \"\")\n",
    "    pass\n",
    "pass"
   ],
   "id": "9b4848d5d10b9627",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos>what are the flanagan motion phases involved in the task- cut the apple. Give it in json\n",
      "format, no further explanation is\n",
      "needed<bos>what are the flanagan motion phases involved in the task- cut the apple. Give it in json format, no further explanation is needed.\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"phase\": \"initial_positioning\",\n",
      "    \"description\": \"Positioning the \n",
      "hand and tool (knife) in front of the apple, ensuring proper alignment for cutting.\",\n",
      "    \"duration\": \n",
      "\"0.1-0.2 seconds\"\n",
      "  },\n",
      "  {\n",
      "    \"phase\": \"approach_and_grip\",\n",
      "    \"description\": \"Moving the knife towards \n",
      "the apple and securely gripping it with the fingers.\",\n",
      "    \"duration\": \"0.2-0.3 seconds\"\n",
      "  },\n",
      "  {\n",
      "    \n",
      "\"phase\": \"cutting_motion\",\n",
      "    \"description\": \"Executing the cutting motion with the knife, applying force \n",
      "to slice through the apple.\",\n",
      "    \"duration\": \"0.5-1.0 seconds\"\n",
      "  },\n",
      "  {\n",
      "    \"phase\": \n",
      "\"separation_and_withdrawal\",\n",
      "    \"description\": \"Separating the cut piece from the apple and smoothly withdrawing the knife.\",\n",
      "\n",
      "    \"duration\": \"0.3-0.4 seconds\"\n",
      "  },\n",
      "  {\n",
      "    \"phase\": \"final_positioning\",\n",
      "    \"description\": \n",
      "\"Adjusting the position of the cut apple and the knife for a clean presentation or further handling.\",\n",
      "    \n",
      "\"duration\": \"0.1-0.2 seconds\"\n",
      "  }\n",
      "]\n",
      "```<end_of_turn>"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "51d6a6dc8606bc6a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsloth",
   "language": "python",
   "name": "unsloth"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
