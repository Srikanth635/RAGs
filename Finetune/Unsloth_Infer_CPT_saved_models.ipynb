{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T09:46:57.959538Z",
     "start_time": "2025-03-19T09:46:53.044071Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from unsloth import FastLanguageModel\n",
    "max_seq_length = 2048\n",
    "dtype = None\n",
    "load_in_4bit = True"
   ],
   "id": "f53b6def241a284",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-18T15:35:14.584515Z",
     "start_time": "2025-03-18T15:35:05.205611Z"
    }
   },
   "source": [
    "if True:\n",
    "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "        model_name = \"lora_model_trained_2\",\n",
    "        max_seq_length = max_seq_length,\n",
    "        dtype=dtype,\n",
    "        load_in_4bit=load_in_4bit\n",
    "    )\n",
    "\n",
    "    FastLanguageModel.for_inference(model)\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\" : \"user\",\n",
    "        \"content\" : \"what are the flanagan motion phases involved in the task- cut the apple, give it in json format, no further explanation is needed\"\n",
    "     }\n",
    "]\n",
    "\n",
    "# input_ids = tokenizer.apply_chat_template(\n",
    "#     messages,\n",
    "#     add_generation_prompt=True,\n",
    "#     return_tensors=\"pt\",\n",
    "# ).to(\"cuda\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.3.15: Fast Mistral patching. Transformers: 4.49.0.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 4070. Num GPUs = 1. Max memory: 11.719 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.9. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Will load lora_model_trained_2 as a legacy tokenizer.\n",
      "Unsloth 2025.3.15 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T15:35:23.198389Z",
     "start_time": "2025-03-18T15:35:17.134140Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import TextIteratorStreamer\n",
    "from threading import Thread\n",
    "text_streamer = TextIteratorStreamer(tokenizer)\n",
    "import textwrap\n",
    "max_print_width = 150\n",
    "\n",
    "prompts = [\n",
    "    \"what are the flanagan motion phases involved in the task- cut the mango with the small black knife. Give it in json format, no further explanation is needed\",\n",
    "    \"what are the motion constraints involved in the task- cut the mango with the small black knife. Give it in json format, no further explanation is needed\",\n",
    "    \"what are the framenet elements involved in the task- cut the mango with the small black knife. Give it in json format, no further explanation is needed\",\n",
    "    \"what is the object information in the task- cut the mango with the small black knife. Give it in json format, no further explanation is needed\"\n",
    "]\n",
    "\n",
    "inputs = tokenizer(\n",
    "[\n",
    "    prompts[0],\n",
    "]*1, return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "generation_kwargs = dict(\n",
    "    inputs,\n",
    "    streamer = text_streamer,\n",
    "    max_new_tokens = 1024,\n",
    "    use_cache = True,\n",
    ")\n",
    "thread = Thread(target = model.generate, kwargs = generation_kwargs)\n",
    "thread.start()\n",
    "\n",
    "length = 0\n",
    "for j, new_text in enumerate(text_streamer):\n",
    "    if j == 0:\n",
    "        wrapped_text = textwrap.wrap(new_text, width = max_print_width)\n",
    "        length = len(wrapped_text[-1])\n",
    "        wrapped_text = \"\\n\".join(wrapped_text)\n",
    "        print(wrapped_text, end = \"\")\n",
    "    else:\n",
    "        length += len(new_text)\n",
    "        if length >= max_print_width:\n",
    "            length = 0\n",
    "            print()\n",
    "        print(new_text, end = \"\")\n",
    "    pass\n",
    "pass"
   ],
   "id": "a5fbacfe0d9e4d64",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>what are the flanagan motion phases involved in the task- cut the mango with the small black knife. Give it in json format, no further explanation\n",
      "isneeded.\n",
      "\n",
      "{\n",
      "\"task\": \"Cut the mango with the small black knife\",\n",
      "\"phases\": {\n",
      "  \"preparation\": {\n",
      "    \"name\": \"approach-mango\",\n",
      "    \"description\": \n",
      "\"approach the mango and position the knife nearby\"\n",
      "  },\n",
      "  \"initial_contact\": {\n",
      "    \"name\": \"grasp-knife\",\n",
      "    \"description\": \"grasp the small black knife \n",
      "firmly\"\n",
      "  },\n",
      "  \"task_specific\": {\n",
      "    \"name\": \"position-knife\",\n",
      "    \"description\": \"position the knife over the mango\"\n",
      "  },\n",
      "  \"task_specific\": {\n",
      "    \"name\": \n",
      "\"apply_force\",\n",
      "    \"description\": \"apply downward force to slice through the mango\"\n",
      "  },\n",
      "  \"withdrawal\": {\n",
      "    \"name\": \"retract_knife\",\n",
      "    \"description\": \"retract \n",
      "the knife after cutting the mango\"\n",
      "  },\n",
      "  \"post_task\": {\n",
      "    \"name\": \"clean_and_store\",\n",
      "    \"description\": \"clean the knife and store it properly\"\n",
      "  }\n",
      "}\n",
      "\n",
      "}\n",
      "</s>"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T10:40:27.498438Z",
     "start_time": "2025-03-18T10:40:27.496673Z"
    }
   },
   "cell_type": "code",
   "source": "# model.save_pretrained_gguf(\"model\", tokenizer = tokenizer)",
   "id": "aad5d4c18bf64ba0",
   "outputs": [],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsloth_finetune",
   "language": "python",
   "name": "finetune"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
