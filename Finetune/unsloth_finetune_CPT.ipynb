{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-18T13:18:37.571451Z",
     "start_time": "2025-03-18T13:18:37.569171Z"
    }
   },
   "source": [
    "import unsloth\n",
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "import os\n",
    "\n",
    "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False."
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T13:18:38.535175Z",
     "start_time": "2025-03-18T13:18:38.531953Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n",
    "fourbit_models = [\n",
    "    \"unsloth/mistral-7b-v0.3-bnb-4bit\",      # New Mistral v3 2x faster!\n",
    "    \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n",
    "    \"unsloth/llama-3-8b-bnb-4bit\",           # Llama-3 15 trillion tokens model 2x faster!\n",
    "    \"unsloth/llama-3-8b-Instruct-bnb-4bit\",\n",
    "    \"unsloth/llama-3-70b-bnb-4bit\",\n",
    "    \"unsloth/Phi-3-mini-4k-instruct\",        # Phi-3 2x faster!\n",
    "    \"unsloth/Phi-3-medium-4k-instruct\",\n",
    "    \"unsloth/mistral-7b-bnb-4bit\",\n",
    "    \"unsloth/gemma-7b-bnb-4bit\",             # Gemma 2.2x faster!\n",
    "] # More models at https://huggingface.co/unsloth"
   ],
   "id": "c906f07e13b1ae20",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T13:18:45.904192Z",
     "start_time": "2025-03-18T13:18:39.715700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/mistral-7b-v0.3\", # \"unsloth/mistral-7b\" for 16bit loading\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
    ")"
   ],
   "id": "6810ee24ea910998",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.3.15: Fast Mistral patching. Transformers: 4.49.0.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 4070. Num GPUs = 1. Max memory: 11.719 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.9. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T13:18:53.297792Z",
     "start_time": "2025-03-18T13:18:49.969439Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 128, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",\n",
    "                      \"embed_tokens\", \"lm_head\",], # Add for continual pretraining\n",
    "    lora_alpha = 32,\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = 3407,\n",
    "    use_rslora = True,  # We support rank stabilized LoRA\n",
    "    loftq_config = None, # And LoftQ\n",
    ")"
   ],
   "id": "a018f0eff03858a2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Offloading input_embeddings to disk to save VRAM\n",
      "Unsloth: Offloading output_embeddings to disk to save VRAM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.3.15 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Training embed_tokens in mixed precision to save VRAM\n",
      "Unsloth: Training lm_head in mixed precision to save VRAM\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T13:18:57.021046Z",
     "start_time": "2025-03-18T13:18:57.016132Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def read_markdown_files(directory):\n",
    "    markdown_contents = []\n",
    "    text_contents = []\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(\".md\"):\n",
    "                file_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    with open(file_path, \"r\", encoding=\"utf-8\", errors='replace') as f:\n",
    "                        content = f.read()\n",
    "                        markdown_contents.append(content)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading file {file_path}: {e}\")\n",
    "            elif file.endswith(\".txt\"):\n",
    "                file_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    with open(file_path, \"r\", encoding=\"utf-8\", errors='replace') as f:\n",
    "                        content = f.read()\n",
    "                        text_contents.append(content)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading file {file_path}: {e}\")\n",
    "\n",
    "    return markdown_contents, text_contents"
   ],
   "id": "958994e780295e63",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T13:18:58.939408Z",
     "start_time": "2025-03-18T13:18:58.876680Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# with open(\"../documentation/basics/GeneralTaskKnowledge/Cutting/Cutting_Locations.md\") as f:\n",
    "#     data1 = f.read()\n",
    "\n",
    "docs_content, text_content = read_markdown_files(os.path.join(os.curdir, \"../documentation\"))"
   ],
   "id": "8b8180b37ada6084",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T13:19:00.963972Z",
     "start_time": "2025-03-18T13:19:00.961701Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from datasets import load_dataset\n",
    "# dataset = load_dataset(\"roneneldan/TinyStories\", split = \"train[:100]\")\n",
    "\n",
    "print(docs_content[2])"
   ],
   "id": "2549708a251baddb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can usability models help robots learn and improve interaction quality through task data and user feedback?Yes, usability models can indeed support learning in robots to enhance usability over time. In fact, considering usability during the design and development of robotic systems is of paramount importance.\n",
      "\n",
      "## Use of Usability Models in Robots\n",
      "\n",
      "Usability models can serve as a guide for how robots should interact with users, helping them to achieve their goals efficiently, effectively, and with a high degree of satisfaction. Over time, as the robot interacts more with its users, it can use these models to learn and adapt itself to better meet the user's needs.\n",
      "\n",
      "## Task Data & User Feedback\n",
      "\n",
      "### Task Data\n",
      "\n",
      "Task data refers to the specific tasks that the robot is programmed to perform. This data can include information on the success or failure of tasks, the time taken to complete tasks, and other metrics that are relevant to the task's performance.\n",
      "\n",
      "Robots can use this data to improve their performance in several ways. For instance:\n",
      "\n",
      "1. **Adaptive Learning**: Robots can recognize patterns in task data, which allows them to predict future outcomes and adjust their behavior accordingly. This results in more efficient task execution.\n",
      "\n",
      "2. **Incremental Learning**: Based on the task data, robots can incrementally refine their skills over time. They can learn more about the tasks they perform and effectively improve their efficiency and accuracy.\n",
      "\n",
      "### User Feedback\n",
      "\n",
      "User feedback is another essential part of the learning process for robots. Feedback can come in various forms, such as direct user ratings, indirect signals from user behavior, or even real-time emotional responses.\n",
      "\n",
      "User feedback can provide valuable insights into how users perceive the robot's performance and interaction quality. For instance:\n",
      "\n",
      "1. **Calibrating Interaction**: Feedback helps robots learn and adapt their characteristics (behavior, speech, movement) to better align with user's preferences, thus enhancing the interaction quality.\n",
      "\n",
      "2. **Performance Enhancement**: Negative feedback can help identify what is not working and provide a chance to improve those areas. Conversely, positive feedback encourages the reinforcement of behaviors that users find satisfying.\n",
      "\n",
      "In summary, robots can leverage usability models, task data and user feedback to self-adjust and improve over time — enhancing usability and interaction quality for a more user-tailored experience.\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T13:19:03.035795Z",
     "start_time": "2025-03-18T13:19:03.031410Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import Dataset, load_dataset, concatenate_datasets\n",
    "data1 = {\"text\": text_content}\n",
    "datasets1 = Dataset.from_dict(data1)"
   ],
   "id": "b1ba35c3d7640fd0",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T13:19:03.361142Z",
     "start_time": "2025-03-18T13:19:03.340649Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import Dataset, load_dataset\n",
    "data2 = {\"text\": docs_content}\n",
    "datasets2 = Dataset.from_dict(data2)"
   ],
   "id": "c7adb1606fe2fab1",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T13:19:03.681893Z",
     "start_time": "2025-03-18T13:19:03.676308Z"
    }
   },
   "cell_type": "code",
   "source": "datasets = concatenate_datasets([datasets1, datasets2])",
   "id": "62c07f162e6d8fa7",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T13:19:04.080547Z",
     "start_time": "2025-03-18T13:19:04.078531Z"
    }
   },
   "cell_type": "code",
   "source": "EOS_TOKEN = tokenizer.eos_token",
   "id": "6dd1db70ceaeafbf",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T13:19:05.747979Z",
     "start_time": "2025-03-18T13:19:05.729717Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def formatting_prompts_func(examples):\n",
    "    return { \"text\" : [example + EOS_TOKEN for example in examples[\"text\"]] }\n",
    "datasets = datasets.map(formatting_prompts_func, batched = True,)"
   ],
   "id": "cae57fe193cc0cda",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/574 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b3c09a04f2a444008575260ab8637ac4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T13:19:06.720949Z",
     "start_time": "2025-03-18T13:19:06.718149Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for row in datasets[3:4][\"text\"]:\n",
    "    print(\"=========================\")\n",
    "    print(row)"
   ],
   "id": "dbad0694fbde651b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================\n",
      "query: cut the apple into 4 equal pieces on the table using the sharp black knife\n",
      "\n",
      "\n",
      "response: comprehensive cram action designator in lisp format is as below\n",
      "(an action\n",
      "    (type cutting)\n",
      "    (object (an object\n",
      "              (type apple)\n",
      "              (name \"standard-apple\")\n",
      "              (properties (size \"medium\")\n",
      "                          (texture \"smooth\")\n",
      "                          (color \"red\")))))\n",
      "    (tool (a tool\n",
      "            (type knife)\n",
      "            (name \"sharp-black-knife\")\n",
      "            (properties (sharpness \"very-high\")\n",
      "                        (size \"medium\")\n",
      "                        (material \"steel\")\n",
      "                        (weight \"light\")\n",
      "                        (color \"black\")\n",
      "                        (edge \"smooth\")))))\n",
      "    (location (a location\n",
      "                (type table)\n",
      "                (name \"kitchen-table\")\n",
      "                (properties (material \"wood\")\n",
      "                            (height 0.9)\n",
      "                            (accessibility \"high\")\n",
      "                            (surface-type \"stable\")))))\n",
      "    (goal (for-object (an object\n",
      "                        (type apple)\n",
      "                        (to be-cut-into-pieces\n",
      "                          (details (type \"quarter\")\n",
      "                                   (size \"equal\")\n",
      "                                   (quantity \"4\"))))))\n",
      "    (task-constraints\n",
      "      (cut-type \"quartered\")\n",
      "      (cut-uniformly \"true\")\n",
      "      (remove-core \"none\")\n",
      "      (remove-seeds \"none\")\n",
      "      (maintain-shape-integrity \"high\"))\n",
      "    (motion-constraints\n",
      "      (kinematic-constraints\n",
      "        (degrees-of-freedom 6)\n",
      "        (workspace (boundaries (x-min 0)\n",
      "                              (x-max 1000)\n",
      "                              (y-min 0)\n",
      "                              (y-max 1000)\n",
      "                              (z-min 0)\n",
      "                              (z-max 500))\n",
      "                   (singularity-tolerance 0.01))\n",
      "        (path-constraints (trajectory-smoothness 0.95)\n",
      "                          (collision-avoidance (enabled true)\n",
      "                                              (proximity-threshold 20))))\n",
      "      (dynamic-constraints\n",
      "        (force-control (normal-force 10)\n",
      "                       (shearing-force 5))\n",
      "        (vibration-control (damping-coefficient 0.8))\n",
      "        (torque-limits (joint-1 (max-torque 10))\n",
      "                       (joint-2 (max-torque 15)))\n",
      "        (inertia-compensation (object-inertia (x 0.003)\n",
      "                                            (y 0.003)\n",
      "                                            (z 0.002))))\n",
      "      (control-constraints\n",
      "        (motion-control (control-mode \"hybrid_force_position\")\n",
      "                        (gain-tuning (proportional-gain 1.0)\n",
      "                                     (derivative-gain 0.6)))\n",
      "        (trajectory-execution (sampling-rate 1000)\n",
      "                              (jerk-limit 30)))\n",
      "      (environmental-constraints\n",
      "        (surface (material \"wood\")\n",
      "                 (friction-coefficient 0.6)\n",
      "                 (flatness-tolerance 0.02))\n",
      "        (obstacle-avoidance (obstacles (type \"bottle\")\n",
      "                                      (position (x 300)\n",
      "                                                (y 300)\n",
      "                                                (z 0))\n",
      "                                      (dimensions (radius 50)))\n",
      "                            (avoidance-radius 20)))\n",
      "      (feedback-constraints\n",
      "        (sensors (force-sensor (sensitivity 0.1)\n",
      "                               (range 30))\n",
      "                 (camera (resolution (width 1920)\n",
      "                                    (height 1080))\n",
      "                         (field-of-view 90)\n",
      "                         (frame-rate 30))\n",
      "                 (tactile-sensor (resolution 0.01)\n",
      "                                 (sensitivity 0.05)))\n",
      "        (latency (control-loop 5)\n",
      "                 (sensor-update-rate 20)))\n",
      "      (safety-constraints\n",
      "        (force-limits (max-interaction-force 15)\n",
      "                      (human-contact-force-threshold 3))\n",
      "        (tool-safety (tool-storage-position (x 0)\n",
      "                                           (y 0)\n",
      "                                           (z 50))\n",
      "                      (disable-tool-when-idle true))\n",
      "        (collision-safety (emergency-stop (trigger-force 10)\n",
      "                                         (response-time 0.1)))))\n",
      "  (flanagan-motion-phases\n",
      "    (pre-motion-phase\n",
      "      (predictive-model\n",
      "        (expected-trajectory \"smooth downward quartering\")\n",
      "        (force-model\n",
      "          (initial-force 1.0)\n",
      "          (resistance-range))\n",
      "        (tool-model\n",
      "          (sharpness \"very-high\")\n",
      "          (length 15)))\n",
      "      (motion-planning\n",
      "        (trajectory \"controlled downward cut\")\n",
      "        (obstacle-avoidance \"none\")\n",
      "        (energy-efficiency \"optimized\")))\n",
      "    (initiation-phase\n",
      "      (initial-state\n",
      "        (robot-position)\n",
      "        (object-position '(0.5 0 0.1))\n",
      "        (tool-position '(0.4 -0.2 0.3)))\n",
      "      (motion-initialization\n",
      "        (joint-activation\n",
      "          (joint1 40)\n",
      "          (joint2 25))\n",
      "        (velocity-profile \"linear ramp-up\")))\n",
      "    (execution-phase\n",
      "      (feedforward-control\n",
      "        (predicted-forces\n",
      "          (initial-force 1.0)\n",
      "          (cutting-force-range))\n",
      "        (predicted-positions\n",
      "          (start '(0.4 -0.2 0.3))\n",
      "          (end '(0.4 -0.2 0.1)))\n",
      "        (error-tolerance\n",
      "          (position-error 0.01)\n",
      "          (force-error 0.05)))\n",
      "      (feedback-control\n",
      "        (corrective-actions\n",
      "          (adjust-trajectory true)\n",
      "          (increase-force true))\n",
      "        (sensor-feedback\n",
      "          (force 1.2)\n",
      "          (position-error 0.01)\n",
      "          (slip-detected false)))\n",
      "      (sensory-integration\n",
      "        (tactile\n",
      "          (gripper-force 3.0)\n",
      "          (cutting-force 1.2))\n",
      "        (visual\n",
      "          (object-center)\n",
      "          (knife-position '(0.4 -0.2 0.18)))\n",
      "        (proprioceptive\n",
      "          (joint-positions)\n",
      "          (joint-velocities))))\n",
      "    (termination-phase\n",
      "      (end-effector-stabilization\n",
      "        (final-position\n",
      "          (knife-position '(0.4 -0.2 0.0)))\n",
      "        (reset-trajectory \"linear reset to neutral position\"))\n",
      "      (success-verification\n",
      "        (outcome-check\n",
      "          (object-cut true)\n",
      "          (pieces-separated true))\n",
      "        (error-analysis\n",
      "          (cut-quality \"smooth\")\n",
      "          (deviation-from-center 0.01))))))\n",
      "</s>\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T10:57:45.315755Z",
     "start_time": "2025-03-18T10:57:44.233974Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "from unsloth import is_bfloat16_supported\n",
    "from unsloth import UnslothTrainer, UnslothTrainingArguments\n",
    "\n",
    "trainer = UnslothTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = datasets,\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dataset_num_proc = 8,\n",
    "\n",
    "    args = UnslothTrainingArguments(\n",
    "        per_device_train_batch_size = 2,\n",
    "        gradient_accumulation_steps = 8,\n",
    "\n",
    "        warmup_ratio = 0.1,\n",
    "        num_train_epochs = 5,\n",
    "\n",
    "        learning_rate = 5e-5,\n",
    "        embedding_learning_rate = 5e-6,\n",
    "        max_steps=100,\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        logging_steps = 1,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.00,\n",
    "        lr_scheduler_type = \"cosine\",\n",
    "        seed = 3407,\n",
    "        output_dir = \"outputs\",\n",
    "        report_to = \"none\", # Use this for WandB etc\n",
    "    ),\n",
    ")"
   ],
   "id": "1fd960b4434f022f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tokenizing to [\"text\"] (num_proc=8):   0%|          | 0/574 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b85c38be26bb4b3d9f90927bd13976d0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T11:26:22.971455Z",
     "start_time": "2025-03-18T10:57:49.867041Z"
    }
   },
   "cell_type": "code",
   "source": "trainer_stats = trainer.train()",
   "id": "637c0e1bf90a114a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 574 | Num Epochs = 3 | Total steps = 100\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 8\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 8 x 1) = 16\n",
      " \"-____-\"     Trainable parameters = 603,979,776/4,362,342,400 (13.85% trained)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 28:11, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.252400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.388000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.286600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.293200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.193300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.130100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.262300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.215400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.156300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.235200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.143200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.089500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.012300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.063000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.012200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.119600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.027800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.079600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.078600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.178600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1.240500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1.145700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1.020500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1.045800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.098700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1.122000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>1.050700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>1.168000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>1.136300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.931500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>1.048700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.995600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>1.023000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>1.051700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.961700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>1.707700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.787800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.681000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.636300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.553000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.638600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.630000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.590600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.567700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.625900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.695300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.593800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.581000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.523000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.532000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.586100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.584800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.512000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.611000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.626800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.449900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.601500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.494000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.549100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.710500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.615500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.545000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.612300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.518500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.497300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.600600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.578100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.660600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.582900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.583500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>1.063900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.267800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.417500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.347600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.453100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.367500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.355400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.411000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.317100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.383000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>0.353000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>0.254400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>0.341700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.302000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.327500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.310900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>0.374700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.354600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>0.295500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.352600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>0.312400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.260500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>0.402500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>0.297000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.318700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.271400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>0.324200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>0.250200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>0.364900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.334200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Inference",
   "id": "b396ea9b705eeb12"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T11:37:25.946973Z",
     "start_time": "2025-03-18T11:37:02.482422Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import TextIteratorStreamer\n",
    "from threading import Thread\n",
    "text_streamer = TextIteratorStreamer(tokenizer)\n",
    "import textwrap\n",
    "max_print_width = 100\n",
    "\n",
    "prompts = [\n",
    "    \"what is the comprehensive action designator for the task- cut the apple. Give it in lisp format, no further explanation is needed\",\n",
    "    \"what are the flanagan motion phases involved in the task- cut the apple. Give it in json format, no further explanation is needed\",\n",
    "    \"what are the motion constraints involved in the task- cut the apple. Give it in json format, no further explanation is needed\",\n",
    "    \"what are the framenet elements involved in the task- cut the apple. Give it in json format, no further explanation is needed\",\n",
    "    \"what are the object and tools involved in the task- cut the apple. Give it in json format, no further explanation is needed\"\n",
    "]\n",
    "\n",
    "inputs = tokenizer(\n",
    "[\n",
    "    prompts[0]\n",
    "]*1, return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "generation_kwargs = dict(\n",
    "    inputs,\n",
    "    streamer = text_streamer,\n",
    "    max_new_tokens = 2048,\n",
    "    use_cache = True,\n",
    ")\n",
    "thread = Thread(target = model.generate, kwargs = generation_kwargs)\n",
    "thread.start()\n",
    "\n",
    "length = 0\n",
    "for j, new_text in enumerate(text_streamer):\n",
    "    if j == 0:\n",
    "        wrapped_text = textwrap.wrap(new_text, width = max_print_width)\n",
    "        length = len(wrapped_text[-1])\n",
    "        wrapped_text = \"\\n\".join(wrapped_text)\n",
    "        print(wrapped_text, end = \"\")\n",
    "    else:\n",
    "        length += len(new_text)\n",
    "        if length >= max_print_width:\n",
    "            length = 0\n",
    "            print()\n",
    "        print(new_text, end = \"\")\n",
    "    pass\n",
    "pass"
   ],
   "id": "ea847c7b6ae3baf7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> what is the comprehensive action designator for the task- cut the apple. Give it in lisp format,\n",
      "no further explanation isneeded.\n",
      "\n",
      "The Comprehensive Action Designator (CAD) for the task \"cut the \n",
      "apple\" in Lisp format would be structured as follows:\n",
      "\n",
      "(an action\n",
      "   (type cutting)\n",
      "   (object (an object\n",
      "\n",
      "             (type apple)\n",
      "             (name \"standard-red-apple\")\n",
      "             (properties (size \"medium\")\n",
      "\n",
      "                         (texture \"smooth\")\n",
      "                         (color \"red\")))))\n",
      "   (tool (a tool\n",
      "          \n",
      " (type knife)\n",
      "           (name \"chef-knife\")\n",
      "           (properties (sharpness \"very-high\")\n",
      "\n",
      "                       (size \"large\")\n",
      "                       (material \"stainless-steel\")\n",
      "                       \n",
      "(weight \"heavy\")\n",
      "                       (color \"silver\")))))\n",
      "   (location (a location\n",
      "               (type \n",
      "cutting-board)\n",
      "               (name \"kitchen-cutting-board\")\n",
      "               (properties (material \"bamboo\")\n",
      "\n",
      "                           (height 0.05)\n",
      "                           (stability \"high\")\n",
      "                           \n",
      "(surface-type \"non-slip\")))))\n",
      "   (goal (for-object (an object\n",
      "                       (type apple)\n",
      "               \n",
      "        (to be-cut-into-pieces\n",
      "                         (details (type \"wedges\")\n",
      "               \n",
      "                   (size \"thick\")\n",
      "                                  (quantity \"multiple\")))))\n",
      "   (task-constraints\n",
      "\n",
      "     (cut-type \"wedges\")\n",
      "     (cut-uniformly \"true\")\n",
      "     (remove-core \"none\")\n",
      "     \n",
      "(maintain-shape-integrity \"high\"))\n",
      "   (motion-constraints\n",
      "     (kinematic-constraints\n",
      "       (degrees-of-freedom 6)\n",
      "       \n",
      "(workspace (boundaries (x-min 0)\n",
      "                             (x-max 1200)\n",
      "                             \n",
      "(y-min 0)\n",
      "                             (y-max 1200)\n",
      "                             (z-min 0)\n",
      "               \n",
      "              (z-max 600))\n",
      "                  (singularity-tolerance 0.015))\n",
      "       (path-constraints \n",
      "(trajectory-smoothness 0.92)\n",
      "                         (collision-avoidance (enabled true)\n",
      "                               \n",
      "              (proximity-threshold 20))))\n",
      "     (dynamic-constraints\n",
      "       (force-control (normal-force 12)\n",
      "\n",
      "                      (shearing-force 8))\n",
      "       (vibration-control (damping-coefficient 0.8))\n",
      "       \n",
      "(torque-limits (joint-1 (max-torque 10))\n",
      "                      (joint-2 (max-torque 15)))\n",
      "       \n",
      "(inertia-compensation (object-inertia (x 0.005)\n",
      "                                           (y 0.005)\n",
      "               \n",
      "                            (z 0.004))))\n",
      "     (control-constraints\n",
      "       (motion-control (control-mode \n",
      "\"hybrid_force_position\")\n",
      "                       (gain-tuning (proportional-gain 1.2)\n",
      "                                    \n",
      "(derivative-gain 0.7)))\n",
      "       (trajectory-execution (sampling-rate 1200)\n",
      "                             (jerk-limit \n",
      "30)))\n",
      "     (environmental-constraints\n",
      "       (surface (material \"bamboo\")\n",
      "                \n",
      "(friction-coefficient 0.5)\n",
      "                (flatness-tolerance 0.01))\n",
      "       (obstacle-avoidance (obstacles (type \n",
      "\"bowl\")\n",
      "                                     (position (x 450)\n",
      "                               \n",
      "                (y 450)\n",
      "                                               (z 0))\n",
      "                               \n",
      "      (dimensions (radius 100)))\n",
      "                           (avoidance-radius 25)))\n",
      "     \n",
      "(feedback-constraints\n",
      "       (sensors (force-sensor (sensitivity 0.1)\n",
      "                              (range 30))\n",
      "\n",
      "                (camera (resolution (width 1920)\n",
      "                                   (height 1080))\n",
      "               \n",
      "         (field-of-view 90)\n",
      "                        (frame-rate 60))\n",
      "                (tactile-sensor \n",
      "(resolution 0.01)\n",
      "                                (sensitivity 0.05)))\n",
      "       (latency (control-loop 5)\n",
      "\n",
      "                (sensor-update-rate 20)))\n",
      "     (safety-constraints\n",
      "       (force-limits (max-interaction-force \n",
      "15)\n",
      "                     (human-contact-force-threshold 4))\n",
      "       (tool-safety (tool-storage-position \n",
      "(x 0)\n",
      "                                          (y 0)\n",
      "                                          (z \n",
      "60))\n",
      "                     (disable-tool-when-idle true))\n",
      "       (collision-safety (emergency-stop \n",
      "(trigger-force 10)\n",
      "                                        (response-time 0.05)))))\n",
      "\n",
      "This CAD provides a detailed \n",
      "action designator for the task \"cut the apple\" by specifying the object, tool, location, goal, task \n",
      "constraints, motion constraints, control constraints, feedback constraints, and safety constraints. Each \n",
      "component is defined with specific properties to ensure a precise and safe execution of the task.</s>"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T11:40:56.636634Z",
     "start_time": "2025-03-18T11:40:56.631676Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "13aa21b009d893b6",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "2eff6e2e7722143b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Saving the model",
   "id": "11b73b813a591c56"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T11:51:41.083586Z",
     "start_time": "2025-03-18T11:51:39.370892Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.save_pretrained(\"lora_model_trained_2\")\n",
    "tokenizer.save_pretrained(\"lora_model_trained_2\")"
   ],
   "id": "17eed8105fa75b35",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('lora_model_trained_2/tokenizer_config.json',\n",
       " 'lora_model_trained_2/special_tokens_map.json',\n",
       " 'lora_model_trained_2/tokenizer.model',\n",
       " 'lora_model_trained_2/added_tokens.json',\n",
       " 'lora_model_trained_2/tokenizer.json')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T10:27:13.362549Z",
     "start_time": "2025-03-18T10:27:10.845224Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if True:\n",
    "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "        model_name = \"lora_model_trained\",\n",
    "        max_seq_length = max_seq_length,\n",
    "        dtype=dtype,\n",
    "        load_in_4bit=load_in_4bit\n",
    "    )\n",
    "\n",
    "    FastLanguageModel.for_inference(model)\n",
    "\n",
    "pass\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\" : \"user\",\n",
    "        \"content\" : \"what are the flanagan motion phases involved in the task- cut the apple, give it in json format, no further explanation is needed\"\n",
    "     }\n",
    "]\n",
    "\n",
    "input_ids = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt=True,\n",
    "    return_tensors=\"pt\",\n",
    ").to(\"cuda\")"
   ],
   "id": "c4cf3479eec225d0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.3.6: Fast Mistral patching. Transformers: 4.48.3.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 4070. Num GPUs = 1. Max memory: 11.719 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.5.1+cu124. CUDA: 8.9. CUDA Toolkit: 12.4. Triton: 3.1.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/malineni/envs/finetune/lib/python3.11/site-packages/accelerate/utils/modeling.py:1536: UserWarning: Current model requires 4194304.0 bytes of buffer for offloaded layers, which seems does not fit any GPU's remaining memory. If you are experiencing a OOM later, please consider using offload_buffers=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit the quantized model. If you want to dispatch the model on the CPU or the disk while keeping these modules in 32-bit, you need to set `llm_int8_enable_fp32_cpu_offload=True` and pass a custom `device_map` to `from_pretrained`. Check https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu for more details. ",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[25]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m     model, tokenizer = \u001B[43mFastLanguageModel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m      3\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mlora_model_trained\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m      4\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmax_seq_length\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_seq_length\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      5\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      6\u001B[39m \u001B[43m        \u001B[49m\u001B[43mload_in_4bit\u001B[49m\u001B[43m=\u001B[49m\u001B[43mload_in_4bit\u001B[49m\n\u001B[32m      7\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      9\u001B[39m     FastLanguageModel.for_inference(model)\n\u001B[32m     11\u001B[39m \u001B[38;5;28;01mpass\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/envs/finetune/lib/python3.11/site-packages/unsloth/models/loader.py:308\u001B[39m, in \u001B[36mFastLanguageModel.from_pretrained\u001B[39m\u001B[34m(model_name, max_seq_length, dtype, load_in_4bit, token, device_map, rope_scaling, fix_tokenizer, trust_remote_code, use_gradient_checkpointing, resize_model_vocab, revision, use_exact_model_name, fast_inference, gpu_memory_utilization, float8_kv_cache, random_state, max_lora_rank, disable_log_stats, *args, **kwargs)\u001B[39m\n\u001B[32m    305\u001B[39m     \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[32m    306\u001B[39m \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m308\u001B[39m model, tokenizer = \u001B[43mdispatch_model\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    309\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m        \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    310\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmax_seq_length\u001B[49m\u001B[43m    \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_seq_length\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    311\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m             \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43m_get_dtype\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    312\u001B[39m \u001B[43m    \u001B[49m\u001B[43mload_in_4bit\u001B[49m\u001B[43m      \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mload_in_4bit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    313\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m             \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    314\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdevice_map\u001B[49m\u001B[43m        \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_map\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    315\u001B[39m \u001B[43m    \u001B[49m\u001B[43mrope_scaling\u001B[49m\u001B[43m      \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mrope_scaling\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    316\u001B[39m \u001B[43m    \u001B[49m\u001B[43mfix_tokenizer\u001B[49m\u001B[43m     \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mfix_tokenizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    317\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmodel_patcher\u001B[49m\u001B[43m     \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mdispatch_model\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    318\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtokenizer_name\u001B[49m\u001B[43m    \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mtokenizer_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    319\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtrust_remote_code\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrust_remote_code\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    320\u001B[39m \u001B[43m    \u001B[49m\u001B[43mrevision\u001B[49m\u001B[43m          \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mrevision\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mis_peft\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    321\u001B[39m \n\u001B[32m    322\u001B[39m \u001B[43m    \u001B[49m\u001B[43mfast_inference\u001B[49m\u001B[43m    \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mfast_inference\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    323\u001B[39m \u001B[43m    \u001B[49m\u001B[43mgpu_memory_utilization\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mgpu_memory_utilization\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    324\u001B[39m \u001B[43m    \u001B[49m\u001B[43mfloat8_kv_cache\u001B[49m\u001B[43m   \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mfloat8_kv_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    325\u001B[39m \u001B[43m    \u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[43m      \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    326\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmax_lora_rank\u001B[49m\u001B[43m     \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_lora_rank\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    327\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdisable_log_stats\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mdisable_log_stats\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    328\u001B[39m \u001B[43m    \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    329\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    331\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m resize_model_vocab \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    332\u001B[39m     model.resize_token_embeddings(resize_model_vocab)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/envs/finetune/lib/python3.11/site-packages/unsloth/models/mistral.py:400\u001B[39m, in \u001B[36mFastMistralModel.from_pretrained\u001B[39m\u001B[34m(model_name, max_seq_length, dtype, load_in_4bit, token, device_map, rope_scaling, fix_tokenizer, model_patcher, tokenizer_name, trust_remote_code, **kwargs)\u001B[39m\n\u001B[32m    385\u001B[39m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[32m    386\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mfrom_pretrained\u001B[39m(\n\u001B[32m    387\u001B[39m     model_name        = \u001B[33m\"\u001B[39m\u001B[33munsloth/mistral-7b-bnb-4bit\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m    398\u001B[39m     **kwargs,\n\u001B[32m    399\u001B[39m ):\n\u001B[32m--> \u001B[39m\u001B[32m400\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mFastLlamaModel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    401\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m        \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    402\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmax_seq_length\u001B[49m\u001B[43m    \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_seq_length\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    403\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m             \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    404\u001B[39m \u001B[43m        \u001B[49m\u001B[43mload_in_4bit\u001B[49m\u001B[43m      \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mload_in_4bit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    405\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m             \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    406\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdevice_map\u001B[49m\u001B[43m        \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_map\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    407\u001B[39m \u001B[43m        \u001B[49m\u001B[43mrope_scaling\u001B[49m\u001B[43m      \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mrope_scaling\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    408\u001B[39m \u001B[43m        \u001B[49m\u001B[43mfix_tokenizer\u001B[49m\u001B[43m     \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mfix_tokenizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    409\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmodel_patcher\u001B[49m\u001B[43m     \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mFastMistralModel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    410\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtokenizer_name\u001B[49m\u001B[43m    \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mtokenizer_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    411\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtrust_remote_code\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrust_remote_code\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    412\u001B[39m \u001B[43m        \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    413\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/envs/finetune/lib/python3.11/site-packages/unsloth/models/llama.py:1769\u001B[39m, in \u001B[36mFastLlamaModel.from_pretrained\u001B[39m\u001B[34m(model_name, max_seq_length, dtype, load_in_4bit, token, device_map, rope_scaling, fix_tokenizer, model_patcher, tokenizer_name, trust_remote_code, fast_inference, gpu_memory_utilization, float8_kv_cache, random_state, max_lora_rank, disable_log_stats, **kwargs)\u001B[39m\n\u001B[32m   1766\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m load_in_4bit: kwargs[\u001B[33m\"\u001B[39m\u001B[33mquantization_config\u001B[39m\u001B[33m\"\u001B[39m] = bnb_config\n\u001B[32m   1768\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m fast_inference:\n\u001B[32m-> \u001B[39m\u001B[32m1769\u001B[39m     model = \u001B[43mAutoModelForCausalLM\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1770\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1771\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdevice_map\u001B[49m\u001B[43m              \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_map\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1772\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtorch_dtype\u001B[49m\u001B[43m             \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1773\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# quantization_config     = bnb_config,\u001B[39;49;00m\n\u001B[32m   1774\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m                   \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1775\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmax_position_embeddings\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_position_embeddings\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1776\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtrust_remote_code\u001B[49m\u001B[43m       \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrust_remote_code\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1777\u001B[39m \u001B[43m        \u001B[49m\u001B[43mattn_implementation\u001B[49m\u001B[43m     \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43meager\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   1778\u001B[39m \u001B[43m        \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1779\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1780\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1781\u001B[39m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01munsloth_zoo\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mvllm_utils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[32m   1782\u001B[39m         load_vllm,\n\u001B[32m   1783\u001B[39m         get_vllm_state_dict,\n\u001B[32m   1784\u001B[39m         convert_vllm_to_huggingface,\n\u001B[32m   1785\u001B[39m         generate_batches,\n\u001B[32m   1786\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/envs/finetune/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:564\u001B[39m, in \u001B[36m_BaseAutoModelClass.from_pretrained\u001B[39m\u001B[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001B[39m\n\u001B[32m    562\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mtype\u001B[39m(config) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mcls\u001B[39m._model_mapping.keys():\n\u001B[32m    563\u001B[39m     model_class = _get_model_class(config, \u001B[38;5;28mcls\u001B[39m._model_mapping)\n\u001B[32m--> \u001B[39m\u001B[32m564\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmodel_class\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    565\u001B[39m \u001B[43m        \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43mmodel_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mhub_kwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[32m    566\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    567\u001B[39m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m    568\u001B[39m     \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mUnrecognized configuration class \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconfig.\u001B[34m__class__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m for this kind of AutoModel: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mcls\u001B[39m.\u001B[34m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m    569\u001B[39m     \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mModel type should be one of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[33m'\u001B[39m\u001B[33m, \u001B[39m\u001B[33m'\u001B[39m.join(c.\u001B[34m__name__\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mfor\u001B[39;00m\u001B[38;5;250m \u001B[39mc\u001B[38;5;250m \u001B[39m\u001B[38;5;129;01min\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28mcls\u001B[39m._model_mapping.keys())\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    570\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/envs/finetune/lib/python3.11/site-packages/transformers/modeling_utils.py:4188\u001B[39m, in \u001B[36mPreTrainedModel.from_pretrained\u001B[39m\u001B[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001B[39m\n\u001B[32m   4185\u001B[39m     device_map = infer_auto_device_map(model, dtype=target_dtype, **device_map_kwargs)\n\u001B[32m   4187\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m hf_quantizer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m4188\u001B[39m         \u001B[43mhf_quantizer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mvalidate_environment\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice_map\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdevice_map\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   4190\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m device_map \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m   4191\u001B[39m     model.tie_weights()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/envs/finetune/lib/python3.11/site-packages/transformers/quantizers/quantizer_bnb_4bit.py:103\u001B[39m, in \u001B[36mBnb4BitHfQuantizer.validate_environment\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m    101\u001B[39m         \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[32m    102\u001B[39m     \u001B[38;5;28;01melif\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mcpu\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m device_map_without_lm_head.values() \u001B[38;5;129;01mor\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mdisk\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m device_map_without_lm_head.values():\n\u001B[32m--> \u001B[39m\u001B[32m103\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m    104\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33mSome modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit the \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    105\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33mquantized model. If you want to dispatch the model on the CPU or the disk while keeping these modules \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    106\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33min 32-bit, you need to set `llm_int8_enable_fp32_cpu_offload=True` and pass a custom `device_map` to \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    107\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33m`from_pretrained`. Check \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    108\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33mhttps://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    109\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33mfor more details. \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    110\u001B[39m         )\n\u001B[32m    112\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m version.parse(importlib.metadata.version(\u001B[33m\"\u001B[39m\u001B[33mbitsandbytes\u001B[39m\u001B[33m\"\u001B[39m)) < version.parse(\u001B[33m\"\u001B[39m\u001B[33m0.39.0\u001B[39m\u001B[33m\"\u001B[39m):\n\u001B[32m    113\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m    114\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mYou have a version of `bitsandbytes` that is not compatible with 4bit inference and training\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    115\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33m make sure you have the latest version of `bitsandbytes` installed\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    116\u001B[39m     )\n",
      "\u001B[31mValueError\u001B[39m: Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit the quantized model. If you want to dispatch the model on the CPU or the disk while keeping these modules in 32-bit, you need to set `llm_int8_enable_fp32_cpu_offload=True` and pass a custom `device_map` to `from_pretrained`. Check https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu for more details. "
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from transformers import TextStreamer\n",
    "text_streamer = TextStreamer(tokenizer, skip_prompt=True)\n",
    "_ = model.generate(input_ids, streamer = text_streamer, max_new_tokens = 128, pad_token_id = tokenizer.eos_token_id)"
   ],
   "id": "69a008cbc37d7295",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Save to 8bit Q8_0\n",
    "if True: model.save_pretrained_gguf(\"model\", tokenizer)\n",
    "\n",
    "# Remember to go to https://huggingface.co/settings/tokens for a token!\n",
    "# And change hf to your username!\n",
    "\n",
    "# if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, token = \"\")\n",
    "\n",
    "# Save to 16bit GGUF\n",
    "# if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"f16\")\n",
    "\n",
    "# if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"f16\", token = \"\")\n",
    "\n",
    "# Save to q4_k_m GGUF\n",
    "# if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"q4_k_m\")\n",
    "\n",
    "# if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"q4_k_m\", token = \"\")\n",
    "\n",
    "# Save to multiple GGUF options much faster if you want multiple!\n",
    "# if False:\n",
    "#     model.push_to_hub_gguf(\n",
    "#         \"hf/model\", # Change hf to your username!\n",
    "#         tokenizer,\n",
    "#         quantization_method = [\"q4_k_m\", \"q8_0\", \"q5_k_m\"],\n",
    "#         token = \"\" # Get a token at https://huggingface.co/settings/tokens\n",
    "#     )"
   ],
   "id": "89490faef297f71"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Widgets Options",
   "id": "80329f4d832a4c00"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T11:44:13.989831Z",
     "start_time": "2025-03-18T11:44:13.985015Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import ipywidgets as widgets\n",
    "# from IPython.display import display\n",
    "#\n",
    "# # Create a dropdown widget for prompt selection\n",
    "# prompt_dropdown = widgets.Dropdown(\n",
    "#     options=prompts,\n",
    "#     description=\"Select Prompt:\",\n",
    "#     disabled=False,\n",
    "# )\n",
    "#\n",
    "# # Create a button to trigger generation\n",
    "# generate_button = widgets.Button(description=\"Generate Response\")\n",
    "#\n",
    "# # Create an output widget to display the generated text\n",
    "# output_widget = widgets.Output()\n",
    "#\n",
    "# def generate_response(b):\n",
    "#     selected_prompt = prompt_dropdown.value\n",
    "#     with output_widget:\n",
    "#         output_widget.clear_output()  # Clear previous output\n",
    "#         print(f\"Generating response for: {selected_prompt}\")\n",
    "#         text_streamer = TextIteratorStreamer(tokenizer)\n",
    "#         max_print_width = 100\n",
    "#\n",
    "#         inputs = tokenizer([selected_prompt], return_tensors=\"pt\").to(\"cuda\")\n",
    "#\n",
    "#         generation_kwargs = dict(\n",
    "#             inputs,\n",
    "#             streamer=text_streamer,\n",
    "#             max_new_tokens=2048,\n",
    "#             use_cache=True,\n",
    "#         )\n",
    "#         thread = Thread(target=model.generate, kwargs=generation_kwargs)\n",
    "#         thread.start()\n",
    "#\n",
    "#         length = 0\n",
    "#         for j, new_text in enumerate(text_streamer):\n",
    "#             if j == 0:\n",
    "#                 wrapped_text = textwrap.wrap(new_text, width=max_print_width)\n",
    "#                 length = len(wrapped_text[-1])\n",
    "#                 wrapped_text = \"\\n\".join(wrapped_text)\n",
    "#                 print(wrapped_text, end=\"\")\n",
    "#             else:\n",
    "#                 length += len(new_text)\n",
    "#                 if length >= max_print_width:\n",
    "#                     length = 0\n",
    "#                     print()\n",
    "#                 print(new_text, end=\"\")\n",
    "#             pass\n",
    "#         print(\"\\n\")\n",
    "#\n",
    "# # Link the button click to the generation function\n",
    "# generate_button.on_click(generate_response)\n",
    "#\n",
    "# # Display the widgets\n",
    "# display(prompt_dropdown, generate_button, output_widget)"
   ],
   "id": "1f3fd4d50bceb2a6",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## GEMMA3",
   "id": "38a8d33747845d34"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T13:22:08.574511Z",
     "start_time": "2025-03-18T13:22:08.538011Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from unsloth import FastModel\n",
    "import torch\n",
    "\n",
    "fourbit_models = [\n",
    "    # 4bit dynamic quants for superior accuracy and low memory use\n",
    "    \"unsloth/gemma-3-1b-it-unsloth-bnb-4bit\",\n",
    "    \"unsloth/gemma-3-4b-it-unsloth-bnb-4bit\",\n",
    "    \"unsloth/gemma-3-12b-it-unsloth-bnb-4bit\",\n",
    "    \"unsloth/gemma-3-27b-it-unsloth-bnb-4bit\",\n",
    "\n",
    "\n",
    "    # Other popular models!\n",
    "    \"unsloth/Llama-3.1-8B\",\n",
    "    \"unsloth/Llama-3.2-3B\",\n",
    "    \"unsloth/Llama-3.3-70B\",\n",
    "    \"unsloth/mistral-7b-instruct-v0.3\",\n",
    "    \"unsloth/Phi-4\",\n",
    "] # More models at https://huggingface.co/unsloth\n",
    "\n",
    "model, tokenizer = FastModel.from_pretrained(\n",
    "    model_name = \"unsloth/gemma-3-4B-it\",\n",
    "    max_seq_length = 2048, # Choose any for long context!\n",
    "    load_in_4bit = True,  # 4 bit quantization to reduce memory\n",
    "    load_in_8bit = False, # [NEW!] A bit more accurate, uses 2x memory\n",
    "    full_finetuning = False, # [NEW!] We have full finetuning now!\n",
    "    # token = \"hf_...\", # use one if using gated models\n",
    ")"
   ],
   "id": "652d6dfbbd73790a",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Unsloth: Gemma 3 only works on transformers >= 4.50.0.\nPlease use nightly transformers via pip install --upgrade \"transformers>=4.49.0\"`",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mRuntimeError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[19]\u001B[39m\u001B[32m, line 20\u001B[39m\n\u001B[32m      2\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\n\u001B[32m      4\u001B[39m fourbit_models = [\n\u001B[32m      5\u001B[39m     \u001B[38;5;66;03m# 4bit dynamic quants for superior accuracy and low memory use\u001B[39;00m\n\u001B[32m      6\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33munsloth/gemma-3-1b-it-unsloth-bnb-4bit\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m     17\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33munsloth/Phi-4\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m     18\u001B[39m ] \u001B[38;5;66;03m# More models at https://huggingface.co/unsloth\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m20\u001B[39m model, tokenizer = \u001B[43mFastModel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     21\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43munsloth/gemma-3-4B-it\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     22\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmax_seq_length\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m2048\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;66;43;03m# Choose any for long context!\u001B[39;49;00m\n\u001B[32m     23\u001B[39m \u001B[43m    \u001B[49m\u001B[43mload_in_4bit\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# 4 bit quantization to reduce memory\u001B[39;49;00m\n\u001B[32m     24\u001B[39m \u001B[43m    \u001B[49m\u001B[43mload_in_8bit\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;66;43;03m# [NEW!] A bit more accurate, uses 2x memory\u001B[39;49;00m\n\u001B[32m     25\u001B[39m \u001B[43m    \u001B[49m\u001B[43mfull_finetuning\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;66;43;03m# [NEW!] We have full finetuning now!\u001B[39;49;00m\n\u001B[32m     26\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# token = \"hf_...\", # use one if using gated models\u001B[39;49;00m\n\u001B[32m     27\u001B[39m \u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/envs/finetune/lib/python3.11/site-packages/unsloth/models/loader.py:518\u001B[39m, in \u001B[36mFastModel.from_pretrained\u001B[39m\u001B[34m(model_name, max_seq_length, dtype, load_in_4bit, load_in_8bit, full_finetuning, token, device_map, rope_scaling, fix_tokenizer, trust_remote_code, use_gradient_checkpointing, resize_model_vocab, revision, return_logits, fullgraph, use_exact_model_name, *args, **kwargs)\u001B[39m\n\u001B[32m    516\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mUnsloth: Aya Vision only works on transformers >= 4.50.0.\u001B[39m\u001B[33m\"\u001B[39m + NIGHTLY)\n\u001B[32m    517\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mgemma-3\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m model_name.lower() \u001B[38;5;129;01mand\u001B[39;00m transformers_version < Version(\u001B[33m\"\u001B[39m\u001B[33m4.50.0.dev0\u001B[39m\u001B[33m\"\u001B[39m):\n\u001B[32m--> \u001B[39m\u001B[32m518\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mUnsloth: Gemma 3 only works on transformers >= 4.50.0.\u001B[39m\u001B[33m\"\u001B[39m + NIGHTLY)\n\u001B[32m    519\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mc4ai-command-a-03-2025\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m model_name.lower() \u001B[38;5;129;01mand\u001B[39;00m transformers_version < Version(\u001B[33m\"\u001B[39m\u001B[33m4.50.0.dev0\u001B[39m\u001B[33m\"\u001B[39m):\n\u001B[32m    520\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mUnsloth: Cohere\u001B[39m\u001B[33m'\u001B[39m\u001B[33ms Command model only works on transformers >= 4.50.0.\u001B[39m\u001B[33m\"\u001B[39m + NIGHTLY)\n",
      "\u001B[31mRuntimeError\u001B[39m: Unsloth: Gemma 3 only works on transformers >= 4.50.0.\nPlease use nightly transformers via pip install --upgrade \"transformers>=4.49.0\"`"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T13:19:52.600623Z",
     "start_time": "2025-03-18T13:19:51.509728Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# !pip install --no-deps git+https://github.com/huggingface/transformers@v4.49.0-Gemma-3\n",
    "# !pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft trl triton cut_cross_entropy unsloth_zoo\n",
    "# !pip install sentencepiece protobuf datasets huggingface_hub hf_transfer\n",
    "# !pip install --no-deps unsloth\n",
    "# !pip install --upgrade --force-reinstall --no-cache-dir unsloth unsloth_zoo\n",
    "!pip install --upgrade \"transformers>=4.49.0\""
   ],
   "id": "18b75ba43d1a7e36",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers>=4.49.0 in /home/malineni/envs/llama/lib/python3.10/site-packages (4.49.0)\r\n",
      "Requirement already satisfied: filelock in /home/malineni/envs/llama/lib/python3.10/site-packages (from transformers>=4.49.0) (3.18.0)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /home/malineni/envs/llama/lib/python3.10/site-packages (from transformers>=4.49.0) (0.29.3)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /home/malineni/envs/llama/lib/python3.10/site-packages (from transformers>=4.49.0) (2.2.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /home/malineni/envs/llama/lib/python3.10/site-packages (from transformers>=4.49.0) (24.2)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/malineni/envs/llama/lib/python3.10/site-packages (from transformers>=4.49.0) (6.0.2)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/malineni/envs/llama/lib/python3.10/site-packages (from transformers>=4.49.0) (2024.11.6)\r\n",
      "Requirement already satisfied: requests in /home/malineni/envs/llama/lib/python3.10/site-packages (from transformers>=4.49.0) (2.32.3)\r\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/malineni/envs/llama/lib/python3.10/site-packages (from transformers>=4.49.0) (0.21.1)\r\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/malineni/envs/llama/lib/python3.10/site-packages (from transformers>=4.49.0) (0.5.3)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/malineni/envs/llama/lib/python3.10/site-packages (from transformers>=4.49.0) (4.67.1)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/malineni/envs/llama/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers>=4.49.0) (2024.12.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/malineni/envs/llama/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers>=4.49.0) (4.12.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/malineni/envs/llama/lib/python3.10/site-packages (from requests->transformers>=4.49.0) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/malineni/envs/llama/lib/python3.10/site-packages (from requests->transformers>=4.49.0) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/malineni/envs/llama/lib/python3.10/site-packages (from requests->transformers>=4.49.0) (2.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/malineni/envs/llama/lib/python3.10/site-packages (from requests->transformers>=4.49.0) (2025.1.31)\r\n"
     ]
    }
   ],
   "execution_count": 16
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsloth_finetune",
   "language": "python",
   "name": "finetune"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
